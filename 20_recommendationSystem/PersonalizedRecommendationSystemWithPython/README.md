# 교재 
> Python을 이용한 개인화 추천 시스템 

# 라이브러리 설치
```bash
python -m pip install pandas
python -m pip install sklearn

```

# 여담
```
낮은 값의 RMSE가 더 좋은 거를 의미합니다

```

# 기본적인 추천 시스템
* basicRecommendation
 - basic.py > 인기순 추천
 - accuracyMeasure.py > 정확도 측정
 - basicGroupRecommendation.py > 그룹별 인기순 추천 
```
그닥 효과적이지않음 
```


# 협업 필터링 CF
> 취향이 비슷한 사람들을 통해서 추천
* collaborativeFiltering
 - basicCFAlgo.py > 기본적인 CF 
 - knnCFAlgo.py > K nearest neighbor 사용한 CF 및 최적의 neighbor사이즈
 - betterCFAlgo.py > 평점 경향을 고려한 CF 

```
취향이 비슷한 네이버를 추려내고 
이 네이버를 통해서 추천한다 

네이버를 추려내려면 유사도 지표가 필요
유사도를 서로 비교하는데 쓰이는 방법 
1. 상관계수
  - 평가자료가 연속값인 경우에 가장 이해하기 쉬운 방법
  - X계산 = rxi - rx표본평균
  - Y계산 = ryi - ry표본평균
  - simil(x, y) = (시그마i->I (X계산 * Y계산)) / 루트(시그마i->I (X계산^2) * 시그마i->I (Y계산^2))
  - rxi 는 i번째 겹치는 아이템의 평점값 이하 동
  - -1(완전반대) 부터 1(완전 일치) 까지 있다
2. 코사인 유사도 
  - 상관계수는 CF 에서 늘 좋지는 않다. 협업 필터링 연속값에서 가장 널리 쓰이는 또다른 방법
  - -1(완전불일치) 1(완전일치)
3. 타니모토 계수 
  - 데이터가 만일 이진값 을 가진다면 위에 있는 상관계수나 코사인 유사도는 쓸 수 없다 
  - 0(완전불일치) 1(완전일치)


유사도평균을 이용한 가중평균을 구해서 했는데 결과가 조금 나아지기는했다.
모든 유저에 대해서 분석을 했기때문이다
취향이 비슷한 집단만 분석을 해서 예측을 하면 조금 더 정확할 것 같다
KNN ( K nearest neighbors, K개만 ) 방식
Threshholding (일정 수치 이상의 유저만 )

취향이 비슷한 집단만 분석을 했더니 RMSE가 1정도에 근사하게 나왔다 더 좋게 나왔다
knn방식으로 이웃의 갯수를 제한했더니 같은 취향의 유저의것을 추천받으니 더 좋게 나온것같다
최적의 이웃의 갯수를 봐야한다. 너무 많거나 너무 적으면 기계학습에서 자주 나오는 문제 과적합(over-fitting)나온다
너무 정확하게 학습해서 예측을 할때 정확도가 떨어지는 것이다.

추천을 하려는 분야(옷, 영화) 에 따라서도 다를수있고, 고객이 누구인지(나이 성별) 에 따라서도 달라질수 있다
이때는 실험을 해야한다
neighbor size를 10부터 60까지 해보고 점점 더 찾아 들어가서 + 1~10 해보고 
한 30 정도로 나왔다 지금 가지고 있는 데이터셋에서는


CF의 정확도를 높일 수 있는 방법 중의 또 다른 하나는
사용자의 평가경향을 고려하는것이다
사용자에따라서 평가를 높게 하는 경향이 있을수도있고 그 역도 있다
평점평균이 3인사람의 4점과 평점평균이 2인사람의 4점의 가치는 다르다 
이걸로 테스트해본결과 
한거랑 안한거랑 완전히 다르다 추천 목록 자체가 다르다

그 외에 신뢰도 가중방법도 있다 
공통아이템 2개 vs 공통아이템 10개는 당연히 후자가 신뢰도가 높다 


아이템기반 CF(IBCF) vs 유저기반 CF(UBCF)
데이터 수가 적을때는 유저기반CF가 터무니없는 추천을 할때가있는데
아이템기반 CF는 그런거 없다
하지만 충분할때는 유저기반이 더 좋다고 들음 
```



# 기타 정보
```
* 수치형 자료 
 1. 연속형 자료 : 키, 몸무게
 2. 이산형 자료 : 교통사고 건수
* 범주형 자료
 1. 순위형 자료 : 평점, 선호도
 2. 명목형 자료 : 혈액형, 성별 

```


# 모델 기반, 메모리 기반
```
추천을 위한 알고리즘을 보면 메모리 기반과 모델 기반으로 나눌 수 있음
메모리 기반은 추천을 위한 데이터를 메모리에 가지고있다가 추천이 필요할때마다 이 데이터로 계산을 해서 추천을 하는 방식

CF가 대표적인 메모리 기반방식

모델 기반 추천은 데이터로부터 추천을 위한 모델을 구성하고 모델을 저장한 다음에 실제 추천할때 모델을 사용해서 추천을 하는 방식
행렬 요인화(Matix Factorization) MF 가 대표적인 모델 기반 추천 알고리즘임 Deep Learning방식도 데이터는 신경망 학습에 사용되고 예측은 만들어진 신경망으로 하니까 
어찌보면 딥러닝도 모델기반 추천 알고리즘이라고도 할 수 있다 

메모리 기반 추천은 모든 데이터를 메모리에 저장하고있기때문에원래 데이터를 충실하게 사용하는 장점이 있다 하지만 대량의 데이터를 다뤄야하는 상용사이트에서는
계산시간이 오래걸리기때문에 빠른반응이 가능하지않다. 하지만 모델 기반 추천 방식은 원래 데이터는 모형을 만드는 데만 사용하고 일단 모델이 만들어지면 원래 데이터는 사용하지 않기 때문에
대규모 상용사이트에서 필요한 빠른 반응이 가능하다, 하지만 모델을 만들려면은 많은 계산 과정이 필요하다

메모리기반은 전체개별 사용자의 데이터에 집중하는데 반해 모델 기반은 전체 사용자의 평가 패턴으로부터 모델을 구성하기 때문에 데이터의 약한신호도 잘 잡는다. 
약한 신호란 전체 데이터에서 완전 소규모 그룹의 평가 패턴을 말한다.
```


# Matix Factoriztion (MF 행렬 요인화)
```
2차원 행렬 (사용자 X 아이템)을 ㅗ구성된 하나의 행렬을 2개의 행렬로 분해하는 바법

2차원행렬 ~~ 사용자잠재행렬(행갯수는 동 열은?) X 아이템잠재행렬(열개수는 동 행은?)
R ~~ P X Q^T == R(hat)
R을 분해한 행렬 두개 P와 Q^T를 곱하면 R과 행열 크기 똑같은 R(hat)이 생긴다
R(hat)은 R의 예측치이며 R(hat)이 R과 최대한 가까운 값을 가지게 하는 P와 Q를 구하면 그것이 바로 추천을 위한 모델이 된다

P와 Q행렬에서 공통인 K개의 요인이 있는데 이것을 (latent factor) 잠재요인이라고 한다 사용자와 아이템의 특성을 K개의 잠재요인을 사용해서 분석하는 모델 

예로 영화의 추천에서 K가2인경우 사용자와 영화의 특성은 2개로 나타낼수있다는 뜻이다 

ex)
사용자 요인 P 
  사용자  잠재요인  액션-드라마 판타지-사실주의
  밥                  -0.41       0.4
  슈
  메리
  앨리스
액션-드라마 컬럼을 예로보면 -1로 갈수록 액션 선호 1로 갈수록 드라마 선호

ex)
아이템 요인 Q
          액션-드라마 판타지-사실주의
  기생충    0.1
위와 동

영화의 특성과 사용자의 특성이 각각 2개의 잠재요인으로 분해되었고 이 잠재요인으로 예상해서 추천을 할 수 있다


SGD (stochastic gradient decent) 를 활용한 MF
어떤 도메인에 대해서 사용자와 아이템의 특성을 잘 설명할 수 있는 K개의 요인이 존재하고 각 사용자와 아이템의 K개 요인에 대한 측정값을 위에 표처럼 알아낼수 있다면
예측값을 채울수 있다. 
실제 평점과 예상 평점의 차이가 정확도가 된다

R로부터 P와 Q를 분해하는알고리즘 순서
1. 잠재요인 K를 정한다, 직관 또는 여러 반복을 통해서 정해도 된다
2. 주어진 K에 따라 P와 Q행렬을 만들고 초기화 한다(P == M X K) (Q == N X K) 맨 처음에는 임의의 수로 채우는 것이 보통
3. 주어진 P Q행렬로 예측평점 R(hat)을 구한다
4. R에 있는 실제 평점에 대해서 예측 평점 Rhat의 예측과 비교해서 오차를 구하고 이 오차를 줄이기 위해서 P와 Q값을 수정한다
5. 전체오차가 미리 정해진 기준값 이하가 되거나 미리 정해진 반복 횟수에 도달할때까지 3으로 가서 반복한다.


핵심은 4에서의 예측 오차를 줄이기 위햇 어떻게 PQ를 수정해야하는가이다
가장 일반적인 방법은 기계학습에 사용되는 SGD방법을 적용하는것 


```