# 교재 
> Python을 이용한 개인화 추천 시스템 

# 라이브러리 설치
```bash
python -m pip install pandas
python -m pip install sklearn

```

# 여담
```
낮은 값의 RMSE가 더 좋은 거를 의미합니다

```

# 기본적인 추천 시스템
* basicRecommendation
 - basic.py > 인기순 추천
 - accuracyMeasure.py > 정확도 측정
 - basicGroupRecommendation.py > 그룹별 인기순 추천 
```
그닥 효과적이지않음 
```


# 협업 필터링
> 취향이 비슷한 사람들을 통해서 추천
* collaborativeFiltering
 - basicCFAlgo.py > 기본적인 CF 
 - knnCFAlgo.py > K nearest neighbor 사용한 CF 및 최적의 neighbor사이즈
 - betterCFAlgo.py > 평점 경향을 고려한 CF 

```
취향이 비슷한 네이버를 추려내고 
이 네이버를 통해서 추천한다 

네이버를 추려내려면 유사도 지표가 필요
유사도를 서로 비교하는데 쓰이는 방법 
1. 상관계수
  - 평가자료가 연속값인 경우에 가장 이해하기 쉬운 방법
  - X계산 = rxi - rx표본평균
  - Y계산 = ryi - ry표본평균
  - simil(x, y) = (시그마i->I (X계산 * Y계산)) / 루트(시그마i->I (X계산^2) * 시그마i->I (Y계산^2))
  - rxi 는 i번째 겹치는 아이템의 평점값 이하 동
  - -1(완전반대) 부터 1(완전 일치) 까지 있다
2. 코사인 유사도 
  - 상관계수는 CF 에서 늘 좋지는 않다. 협업 필터링 연속값에서 가장 널리 쓰이는 또다른 방법
  - -1(완전불일치) 1(완전일치)
3. 타니모토 계수 
  - 데이터가 만일 이진값 을 가진다면 위에 있는 상관계수나 코사인 유사도는 쓸 수 없다 
  - 0(완전불일치) 1(완전일치)


유사도평균을 이용한 가중평균을 구해서 했는데 결과가 조금 나아지기는했다.
모든 유저에 대해서 분석을 했기때문이다
취향이 비슷한 집단만 분석을 해서 예측을 하면 조금 더 정확할 것 같다
KNN ( K nearest neighbors, K개만 ) 방식
Threshholding (일정 수치 이상의 유저만 )

취향이 비슷한 집단만 분석을 했더니 RMSE가 1정도에 근사하게 나왔다 더 좋게 나왔다
knn방식으로 이웃의 갯수를 제한했더니 같은 취향의 유저의것을 추천받으니 더 좋게 나온것같다
최적의 이웃의 갯수를 봐야한다. 너무 많거나 너무 적으면 기계학습에서 자주 나오는 문제 과적합(over-fitting)나온다
너무 정확하게 학습해서 예측을 할때 정확도가 떨어지는 것이다.

추천을 하려는 분야(옷, 영화) 에 따라서도 다를수있고, 고객이 누구인지(나이 성별) 에 따라서도 달라질수 있다
이때는 실험을 해야한다
neighbor size를 10부터 60까지 해보고 점점 더 찾아 들어가서 + 1~10 해보고 
한 30 정도로 나왔다 지금 가지고 있는 데이터셋에서는


CF의 정확도를 높일 수 있는 방법 중의 또 다른 하나는
사용자의 평가경향을 고려하는것이다
사용자에따라서 평가를 높게 하는 경향이 있을수도있고 그 역도 있다
평점평균이 3인사람의 4점과 평점평균이 2인사람의 4점의 가치는 다르다 
이걸로 테스트해본결과 
한거랑 안한거랑 완전히 다르다 추천 목록 자체가 다르다

그 외에 신뢰도 가중방법도 있다 
공통아이템 2개 vs 공통아이템 10개는 당연히 후자가 신뢰도가 높다 
```



# 기타 정보
```
* 수치형 자료 
 1. 연속형 자료 : 키, 몸무게
 2. 이산형 자료 : 교통사고 건수
* 범주형 자료
 1. 순위형 자료 : 평점, 선호도
 2. 명목형 자료 : 혈액형, 성별 

```